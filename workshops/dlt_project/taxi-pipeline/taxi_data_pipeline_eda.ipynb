{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec4a45d4",
   "metadata": {},
   "source": [
    "# Taxi Data EDA Using dlt\n",
    "1. Import Libraries\n",
    "2. Define the API Source\n",
    "3. Create the dlt pipeline\n",
    "\t- a. Extract the data `extract_info = pipeline.extract(openlibrary_source())`\n",
    "\t- b. Normalize the data `normalize_info = pipeline.normalize()`\n",
    "\t- c. Load the data into tables `load_info = pipeline.load()`\n",
    "4. Run the entire pipeline `load_info = pipeline.run(openlibrary_source())`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e112eae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 Import Libraries\n",
    "import dlt\n",
    "import dlt\n",
    "from itertools import islice\n",
    "from dlt.sources.rest_api import rest_api_source\n",
    "from dlt.sources.rest_api import rest_api_resources\n",
    "from dlt.sources.rest_api.typing import RESTAPIConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cb2440",
   "metadata": {},
   "source": [
    "## Breaking it down step by step first\n",
    "- Define Source\n",
    "- Extract Data\n",
    "- Normalize Data\n",
    "- Load Data into DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd7217ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Define API Source\n",
    "def taxi_demo_pipeline_rest_api_source():\n",
    "    \"\"\"Define dlt resources from REST API endpoints.\"\"\"\n",
    "    return rest_api_source({\n",
    "        \"client\": {\n",
    "            # Base URL for the REST API\n",
    "            \"base_url\": \"https://us-central1-dlthub-analytics.cloudfunctions.net/data_engineering_zoomcamp_api\",\n",
    "            # No authentication required\n",
    "            \"auth\": None,\n",
    "            # Pagination using JSON Link header\n",
    "            \"paginator\": {\n",
    "                \"type\": \"json_link\",\n",
    "                \"next_url_path\": \"paging.next\",\n",
    "            },\n",
    "        },\n",
    "        \"resources\": [\n",
    "            # Define resource for the taxi data endpoint\n",
    "            {\n",
    "                \"name\": \"taxi_data_demo\",\n",
    "                \"table_name\": \"taxi_data_demo\",\n",
    "                \"endpoint\": {\n",
    "                    \"path\": \"/\",\n",
    "                    \"params\": {\n",
    "                        \"page\": 1,  # Start from page 1\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "        # Set default configuration for all resources\n",
    "        \"resource_defaults\": {\n",
    "            \"write_disposition\": \"append\",\n",
    "        },\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2927ad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Create the dlt Pipeline\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"taxi_pipeline_demo\",\n",
    "    destination=\"duckdb\",\n",
    "    dataset_name=\"taxi_test_data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f89b694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 - Extract data from source\n",
    "extract_info = pipeline.extract(taxi_demo_pipeline_rest_api_source())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99e27628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resources: ['taxi_data_demo']\n",
      "Tables: ['taxi_data_demo']\n",
      "Load ID: 1771448393.794041\n",
      "\n",
      "Resource: taxi_data_demo\n",
      "rows extracted: 1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reviewing extraction summary data\n",
    "load_id = extract_info.loads_ids[-1]\n",
    "m = extract_info.metrics[load_id][0]\n",
    "\n",
    "print(\"Resources:\", list(m[\"resource_metrics\"].keys()))\n",
    "print(\"Tables:\", list(m[\"table_metrics\"].keys()))\n",
    "print(\"Load ID:\", load_id)\n",
    "print()\n",
    "\n",
    "for resource, rm in m[\"resource_metrics\"].items():\n",
    "    print(f\"Resource: {resource}\")\n",
    "    print(f\"rows extracted: {rm.items_count}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54e05d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 16:01:18,958|[WARNING]|76598|123130724345664|dlt|normalize.py|run:325|When normalizing package 1771448227.5911322 with schema rest_api: the storage schema hash OhpOeAxCbEiN4ojrSInJzEchlZ+fPQMwpsB0NnLFJf8= is different from extract package schema hash G0U/Hj/QZTap37oLt94suYH835Jw0h/0q5edybH0QVs=. Storage schema was used.\n",
      "2026-02-18 16:01:19,169|[WARNING]|76598|123130724345664|dlt|validate.py|verify_normalized_table:91|In schema `rest_api`: The following columns in table 'taxi_data' did not receive any data during this load and therefore could not have their types inferred:\n",
      "  - rate_code\n",
      "  - mta_tax\n",
      "\n",
      "Unless type hints are provided, these columns will not be materialized in the destination.\n",
      "One way to provide type hints is to use the 'columns' argument in the '@dlt.resource' decorator.  For example:\n",
      "\n",
      "@dlt.resource(columns={'rate_code': {'data_type': 'text'}})\n",
      "\n",
      "2026-02-18 16:01:19,180|[WARNING]|76598|123130724345664|dlt|normalize.py|run:325|When normalizing package 1771448393.794041 with schema rest_api: the storage schema hash 3ZKdTBlKsyibd1Ic9/w79BJ6Hk/RCYN8Y7yDk+293XE= is different from extract package schema hash OhpOeAxCbEiN4ojrSInJzEchlZ+fPQMwpsB0NnLFJf8=. Storage schema was used.\n",
      "2026-02-18 16:01:19,387|[WARNING]|76598|123130724345664|dlt|validate.py|verify_normalized_table:91|In schema `rest_api`: The following columns in table 'taxi_data_demo' did not receive any data during this load and therefore could not have their types inferred:\n",
      "  - rate_code\n",
      "  - mta_tax\n",
      "\n",
      "Unless type hints are provided, these columns will not be materialized in the destination.\n",
      "One way to provide type hints is to use the 'columns' argument in the '@dlt.resource' decorator.  For example:\n",
      "\n",
      "@dlt.resource(columns={'rate_code': {'data_type': 'text'}})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 5 Normalize\n",
    "normalize_info = pipeline.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0b239ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load ID: 1771448393.794041\n",
      "\n",
      "Tables created/updated:\n",
      "  - taxi_data_demo: 1000 rows\n"
     ]
    }
   ],
   "source": [
    "# Normalize Info\n",
    "load_id = normalize_info.loads_ids[-1]\n",
    "m = normalize_info.metrics[load_id][0]\n",
    "\n",
    "print(\"Load ID:\", load_id)\n",
    "print()\n",
    "\n",
    "print(\"Tables created/updated:\")\n",
    "for table_name, tm in m[\"table_metrics\"].items():\n",
    "    # skip dlt internal tables to keep it beginner-friendly\n",
    "    if table_name.startswith(\"_dlt\"):\n",
    "        continue\n",
    "    print(f\"  - {table_name}: {tm.items_count} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d234f691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: 4\n",
      "version_hash: ocQFiF+Y1Dd8HlWZJPKkxoXzZCZJNG7y4o66NEv2y6o=\n",
      "engine_version: 11\n",
      "name: rest_api\n",
      "tables:\n",
      "  _dlt_version:\n",
      "    columns:\n",
      "      version:\n",
      "        data_type: bigint\n",
      "        nullable: false\n",
      "      engine_version:\n",
      "        data_type: bigint\n",
      "        nullable: false\n",
      "      inserted_at:\n",
      "        data_type: timestamp\n",
      "        nullable: false\n",
      "      schema_name:\n",
      "        data_type: text\n",
      "        nullable: false\n",
      "      version_hash:\n",
      "        data_type: text\n",
      "        nullable: false\n",
      "      schema:\n",
      "        data_type: text\n",
      "        nullable: false\n",
      "    write_disposition: skip\n",
      "    resource: _dlt_version\n",
      "    description: Created by DLT. Tracks schema updates\n",
      "  _dlt_loads:\n",
      "    columns:\n",
      "      load_id:\n",
      "        data_type: text\n",
      "        nullable: false\n",
      "        precision: 64\n",
      "      schema_name:\n",
      "        data_type: text\n",
      "        nullable: true\n",
      "      status:\n",
      "        data_type: bigint\n",
      "        nullable: false\n",
      "      inserted_at:\n",
      "        data_type: timestamp\n",
      "        nullable: false\n",
      "      schema_version_hash:\n",
      "        data_type: text\n",
      "        nullable: true\n",
      "    write_disposition: skip\n",
      "    resource: _dlt_loads\n",
      "    description: Created by DLT. Tracks completed loads\n",
      "  taxi_data:\n",
      "    columns:\n",
      "      end_lat:\n",
      "        data_type: double\n",
      "        nullable: true\n",
      "      end_lon:\n",
      "        data_type: double\n",
      "        nullable: true\n",
      "      fare_amt:\n",
      "        data_type: double\n",
      "        nullable: true\n",
      "      passenger_count:\n",
      "        data_type: bigint\n",
      "        nullable: true\n",
      "      payment_type:\n",
      "        data_type: text\n",
      "        nullable: true\n",
      "      rate_code:\n",
      "        nullable: true\n",
      "        x-normalizer:\n",
      "          seen-null-first: true\n",
      "      start_lat:\n",
      "        data_type: double\n",
      "        nullable: true\n",
      "      start_lon:\n",
      "        data_type: double\n",
      "        nullable: true\n",
      "      tip_amt:\n",
      "        data_type: double\n",
      "        nullable: true\n",
      "      tolls_amt:\n",
      "        data_type: double\n",
      "        nullable: true\n",
      "      total_amt:\n",
      "        data_type: double\n",
      "        nullable: true\n",
      "      trip_distance:\n",
      "        data_type: double\n",
      "        nullable: true\n",
      "      trip_dropoff_date_time:\n",
      "        data_type: timestamp\n",
      "        nullable: true\n",
      "      trip_pickup_date_time:\n",
      "        data_type: timestamp\n",
      "        nullable: true\n",
      "      mta_tax:\n",
      "        nullable: true\n",
      "        x-normalizer:\n",
      "          seen-null-first: true\n",
      "      surcharge:\n",
      "        data_type: double\n",
      "        nullable: true\n",
      "      vendor_name:\n",
      "        data_type: text\n",
      "        nullable: true\n",
      "      _dlt_load_id:\n",
      "        data_type: text\n",
      "        nullable: false\n",
      "      _dlt_id:\n",
      "        data_type: text\n",
      "        nullable: false\n",
      "        unique: true\n",
      "        row_key: true\n",
      "      store_and_forward:\n",
      "        nullable: true\n",
      "        data_type: double\n",
      "    write_disposition: append\n",
      "    resource: taxi_data\n",
      "    x-normalizer:\n",
      "      seen-data: true\n",
      "  _dlt_pipeline_state:\n",
      "    columns:\n",
      "      version:\n",
      "        data_type: bigint\n",
      "        nullable: false\n",
      "      engine_version:\n",
      "        data_type: bigint\n",
      "        nullable: false\n",
      "      pipeline_name:\n",
      "        data_type: text\n",
      "        nullable: false\n",
      "      state:\n",
      "        data_type: text\n",
      "        nullable: false\n",
      "      created_at:\n",
      "        data_type: timestamp\n",
      "        nullable: false\n",
      "      version_hash:\n",
      "        data_type: text\n",
      "        nullable: true\n",
      "      _dlt_load_id:\n",
      "        data_type: text\n",
      "        nullable: false\n",
      "        precision: 64\n",
      "      _dlt_id:\n",
      "        data_type: text\n",
      "        nullable: false\n",
      "        unique: true\n",
      "        row_key: true\n",
      "    write_disposition: append\n",
      "    file_format: preferred\n",
      "    resource: _dlt_pipeline_state\n",
      "    x-normalizer:\n",
      "      seen-data: true\n",
      "  taxi_data_demo:\n",
      "    columns:\n",
      "      end_lat:\n",
      "        data_type: double\n",
      "        nullable: true\n",
      "      end_lon:\n",
      "        data_type: double\n",
      "        nullable: true\n",
      "      fare_amt:\n",
      "        data_type: double\n",
      "        nullable: true\n",
      "      passenger_count:\n",
      "        data_type: bigint\n",
      "        nullable: true\n",
      "      payment_type:\n",
      "        data_type: text\n",
      "        nullable: true\n",
      "      rate_code:\n",
      "        nullable: true\n",
      "        x-normalizer:\n",
      "          seen-null-first: true\n",
      "      start_lat:\n",
      "        data_type: double\n",
      "        nullable: true\n",
      "      start_lon:\n",
      "        data_type: double\n",
      "        nullable: true\n",
      "      tip_amt:\n",
      "        data_type: double\n",
      "        nullable: true\n",
      "      tolls_amt:\n",
      "        data_type: double\n",
      "        nullable: true\n",
      "      total_amt:\n",
      "        data_type: double\n",
      "        nullable: true\n",
      "      trip_distance:\n",
      "        data_type: double\n",
      "        nullable: true\n",
      "      trip_dropoff_date_time:\n",
      "        data_type: timestamp\n",
      "        nullable: true\n",
      "      trip_pickup_date_time:\n",
      "        data_type: timestamp\n",
      "        nullable: true\n",
      "      mta_tax:\n",
      "        nullable: true\n",
      "        x-normalizer:\n",
      "          seen-null-first: true\n",
      "      surcharge:\n",
      "        data_type: double\n",
      "        nullable: true\n",
      "      vendor_name:\n",
      "        data_type: text\n",
      "        nullable: true\n",
      "      _dlt_load_id:\n",
      "        data_type: text\n",
      "        nullable: false\n",
      "      _dlt_id:\n",
      "        data_type: text\n",
      "        nullable: false\n",
      "        unique: true\n",
      "        row_key: true\n",
      "      store_and_forward:\n",
      "        nullable: true\n",
      "        data_type: double\n",
      "    write_disposition: append\n",
      "    resource: taxi_data_demo\n",
      "    x-normalizer:\n",
      "      seen-data: true\n",
      "settings:\n",
      "  detections:\n",
      "  - iso_timestamp\n",
      "  default_hints:\n",
      "    not_null:\n",
      "    - _dlt_id\n",
      "    - _dlt_root_id\n",
      "    - _dlt_parent_id\n",
      "    - _dlt_list_idx\n",
      "    - _dlt_load_id\n",
      "    parent_key:\n",
      "    - _dlt_parent_id\n",
      "    root_key:\n",
      "    - _dlt_root_id\n",
      "    unique:\n",
      "    - _dlt_id\n",
      "    row_key:\n",
      "    - _dlt_id\n",
      "normalizers:\n",
      "  names: snake_case\n",
      "  json:\n",
      "    module: dlt.common.normalizers.json.relational\n",
      "previous_hashes:\n",
      "- 3ZKdTBlKsyibd1Ic9/w79BJ6Hk/RCYN8Y7yDk+293XE=\n",
      "- OhpOeAxCbEiN4ojrSInJzEchlZ+fPQMwpsB0NnLFJf8=\n",
      "- G0U/Hj/QZTap37oLt94suYH835Jw0h/0q5edybH0QVs=\n",
      "- HYDxw74GF405u/vvUmEGJrko+c6qvd4OSNZLyBWG7SE=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display schema \n",
    "print(pipeline.default_schema.to_pretty_yaml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3d4570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6 Load data into DuckDB\n",
    "load_info = pipeline.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a648c04",
   "metadata": {},
   "source": [
    "## Step 7 - Running Entire Pipeline End-to-End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a7c0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the API Source\n",
    "# if no argument is provided, `access_token` is read from `.dlt/secrets.toml`\n",
    "@dlt.source\n",
    "def taxi_pipeline_rest_api_source():\n",
    "    \"\"\"Define dlt resources from REST API endpoints.\"\"\"\n",
    "    config: RESTAPIConfig = {\n",
    "        \"client\": {\n",
    "            # TODO set base URL for the REST API\n",
    "            \"base_url\": \"https://us-central1-dlthub-analytics.cloudfunctions.net/data_engineering_zoomcamp_api\",\n",
    "            # TODO configure the right authentication method or remove\n",
    "            # \"auth\": {\"type\": \"bearer\", \"token\": access_token},\n",
    "            \"paginator\": {\n",
    "                \"type\": \"json_link\",\n",
    "                \"next_url_path\": \"paging.next\",\n",
    "        \n",
    "            },\n",
    "        },\n",
    "        \"resources\": [\n",
    "            # Define resource for the taxi data endpoint\n",
    "            {\n",
    "                \"name\": \"taxi_data\",\n",
    "                \"table_name\": \"taxi_data\",\n",
    "                \"endpoint\": {\n",
    "                    \"path\": \"/\",\n",
    "                    \"params\": {\n",
    "                        \"page\": 1,  # Start from page 1\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "        # Set default configuration for all resources\n",
    "        \"resource_defaults\": {\n",
    "            \"write_disposition\": \"append\"\n",
    "        },\n",
    "    }\n",
    "\n",
    "    yield from rest_api_resources(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824a4d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipeline - Extract, Normalize, Load in DuckDB\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name='taxi_pipeline_pipeline',\n",
    "    destination='duckdb',\n",
    "    # `refresh=\"drop_sources\"` ensures the data and the state is cleaned\n",
    "    # on each `pipeline.run()`; remove the argument once you have a\n",
    "    # working pipeline.\n",
    "    refresh=\"drop_sources\",\n",
    "    # show basic progress of resources extracted, normalized files and load-jobs on stdout\n",
    "    progress=\"log\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a1d020",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-18 16:08:53,011|[WARNING]|76598|123130724345664|dlt|validate.py|verify_normalized_table:91|In schema `rest_api`: The following columns in table 'taxi_data' did not receive any data during this load and therefore could not have their types inferred:\n",
      "  - rate_code\n",
      "  - mta_tax\n",
      "\n",
      "Unless type hints are provided, these columns will not be materialized in the destination.\n",
      "One way to provide type hints is to use the 'columns' argument in the '@dlt.resource' decorator.  For example:\n",
      "\n",
      "@dlt.resource(columns={'rate_code': {'data_type': 'text'}})\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LoadInfo(pipeline=<dlt.pipeline(pipeline_name='taxi_pipeline_demo', destination='duckdb', dataset_name='taxi_test_data', default_schema_name='rest_api', schema_names=['rest_api'], first_run=False, dev_mode=False, is_active=True, pipelines_dir='/home/user1129/.dlt/pipelines', working_dir='/home/user1129/.dlt/pipelines/taxi_pipeline_demo')>, metrics={'1771448930.0912588': [{'started_at': DateTime(2026, 2, 18, 21, 8, 53, 24274, tzinfo=Timezone('UTC')), 'finished_at': DateTime(2026, 2, 18, 21, 8, 53, 407893, tzinfo=Timezone('UTC')), 'job_metrics': {'taxi_data.8f943e9065.insert_values.gz': LoadJobMetrics(job_id='taxi_data.8f943e9065.insert_values.gz', file_path='/home/user1129/.dlt/pipelines/taxi_pipeline_demo/load/normalized/1771448930.0912588/started_jobs/taxi_data.8f943e9065.0.insert_values.gz', table_name='taxi_data', started_at=DateTime(2026, 2, 18, 21, 8, 53, 65311, tzinfo=Timezone('UTC')), finished_at=DateTime(2026, 2, 18, 21, 8, 53, 290699, tzinfo=Timezone('UTC')), state='completed', remote_url=None, retry_count=0)}}]}, destination_type='dlt.destinations.duckdb', destination_displayable_credentials='duckdb:////home/user1129/MyDocuments/10_14_Life_Admin/13_Technology/100_Coding/100_01_Python/data_engineering/data_engineering_zoom_camp/workshops/dlt_project/taxi-pipeline/taxi_pipeline_demo.duckdb', destination_name='duckdb', environment=None, staging_type=None, staging_name=None, staging_displayable_credentials=None, destination_fingerprint='', dataset_name='taxi_test_data', loads_ids=['1771448930.0912588'], load_packages=[LoadPackageInfo(load_id='1771448930.0912588', package_path='/home/user1129/.dlt/pipelines/taxi_pipeline_demo/load/loaded/1771448930.0912588', state='loaded', schema=<dlt.Schema(name='rest_api', version=4, tables=['_dlt_version', '_dlt_loads', 'taxi_data', '_dlt_pipeline_state', 'taxi_data_demo'], version_hash='ocQFiF+Y1Dd8HlWZJPKkxoXzZCZJNG7y4o66NEv2y6o=')>, schema_update={}, completed_at=DateTime(2026, 2, 18, 21, 8, 53, 405251, tzinfo=Timezone('UTC')), jobs={'completed_jobs': [LoadJobInfo(state='completed_jobs', file_path='/home/user1129/.dlt/pipelines/taxi_pipeline_demo/load/loaded/1771448930.0912588/completed_jobs/taxi_data.8f943e9065.0.insert_values.gz', file_size=46357, created_at=DateTime(2026, 2, 18, 21, 8, 53, 11593, tzinfo=Timezone('UTC')), elapsed=0.3936581611633301, job_file_info=ParsedLoadJobFileName(table_name='taxi_data', file_id='8f943e9065', retry_count=0, file_format='insert_values', is_compressed=True), failed_message=None)], 'failed_jobs': [], 'started_jobs': [], 'new_jobs': []})], first_run=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running the Pipeline\n",
    "load_info = pipeline.run(taxi_pipeline_rest_api_source())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dceb8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
